{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af855268",
   "metadata": {},
   "source": [
    "<a href='https://ai.meng.duke.edu'> = <img align=\"left\" style=\"padding-top:10px;\" src=https://storage.googleapis.com/aipi_datasets/Duke-AIPI-Logo.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab2fed8",
   "metadata": {},
   "source": [
    "# Topic Modeling with Latent Dirichlet Allocation (LDA) and Latent Semantic Analysis (LSA)\n",
    "Topic modeling involves identifying the primary topic(s) for a text document or within a set of documents.  There are topic modeling approaches which use supervised learning to perform multi-class multi-label classification of documents, but this type of approach requires a large labeled training dataset, which we do not always have available.  In this notebook we will explore unsupervised topic modeling approaches using Latent Dirichlet Allocation (LDA) and Latent Semantic Analysis (LSA).  The \"topics\" produced by unsupervised topic modeling techniques are actually clusters of similar words found in the document(s). The topic model discovers these word clusters based on the frequency of the words in each document and attempts to model what the topics might be and what each document's balance of topics is.\n",
    "\n",
    "Topic modeling can be used to extract the main topic(s) from a single document or a collection of documents - in this notebook we will demonstrate topic modeling for a small collection of articles from the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf5c740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/aipi540-s23/ak704/miniconda3/envs/aipi540/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import spacy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c3cb6",
   "metadata": {},
   "source": [
    "## Get documents to tag with topics\n",
    "We will use BeautifulSoup to get the content of a few articles from the web and strip the text content from the hmtl.  The articles we will use for this example are news articles each relating to one or both of two primary themes: COVID-19 and Duke basketball.  Therefore we would expect the topics which we identify to be related to these two themes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e453c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get article\n",
    "article_urls = ['https://www.cbssports.com/college-basketball/news/duke-basketballs-game-vs-clemson-postponed-due-to-positive-covid-19-tests-in-blue-devils-program/',\n",
    "                'https://www.usatoday.com/story/news/health/2021/12/21/covid-holiday-safety-need-to-know/8968198002/',\n",
    "                'https://www.fayobserver.com/story/sports/college/basketball/2021/12/29/duke-blue-devils-basketball-recruiting-jon-scheyer-commits/9032663002/',\n",
    "                'https://www.today.com/health/health/covid-19-cold-flu-tell-difference-rcna10114',\n",
    "                'https://www.dukechronicle.com/article/2021/06/duke-mens-basketball-head-coach-jon-scheyer-mike-krzyzewski',\n",
    "                'https://www.hopkinsmedicine.org/health/conditions-and-diseases/coronavirus']\n",
    "article_text = []\n",
    "titles = []\n",
    "for url in article_urls:\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Extract body text from article\n",
    "    bodytext = soup.find_all('p')\n",
    "    bodytext = [i.text for i in bodytext]\n",
    "    bodytext = ' '.join(bodytext)\n",
    "    article_text.append(bodytext)\n",
    "    # Extract titles for articles\n",
    "    title = soup.find_all('h1')\n",
    "    title = title[0].text.strip()\n",
    "    titles.append(title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc2fd80a-c394-4ae1-991f-18b2ac7c5641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"../data/tripadvisor_hotel_reviews.csv\")\n",
    "article_text = list(data.Review)\n",
    "article_text = article_text[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9381a09",
   "metadata": {},
   "source": [
    "## Create features using Word Counts or TF-IDF\n",
    "Before we can apply a topic model on our set of documents, we must first convert each document into a numeric feature vector.  We can use count vectorization or TF-IDF to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "196d4ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(documents, vectorizer_type='count'):\n",
    "    # Use both 1-grams and 2-grams\n",
    "    n_gram_range = (1, 2)\n",
    "\n",
    "    if vectorizer_type == 'count':\n",
    "        vectorizer = CountVectorizer(max_df=0.6,ngram_range=n_gram_range,\n",
    "                                    stop_words=stopwords.words('english'))\n",
    "        feature_vecs = vectorizer.fit_transform(documents)\n",
    "        feature_vecs = feature_vecs.todense().tolist()\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(max_df=0.6,ngram_range=n_gram_range,\n",
    "                                    stop_words=stopwords.words('english'))\n",
    "        feature_vecs = vectorizer.fit_transform(documents)\n",
    "        feature_vecs = feature_vecs.todense().tolist()\n",
    "        \n",
    "    return feature_vecs, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2812e03a",
   "metadata": {},
   "source": [
    "## Model topics using LDA or LSA\n",
    "Now that our documents are represented by numeric feature vectors, we can apply our topic model.  When fitting the model, we need to select the number of topics we wish to include in our final list, which will correspond to the top n components extracted by LDA or LSA.\n",
    "\n",
    "Each topic is represented by a cluster of similar keywords.  When printing our topic we can also select how many keywords we want to include to represent each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6060f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_topics(vectorized_text,vectorizer,n_topics,n_words,model_type):\n",
    "    if model_type=='lda':\n",
    "        # Perform LDA \n",
    "        model = LatentDirichletAllocation(n_components=n_topics,learning_method='online', random_state=1)\n",
    "        topic_assignments = model.fit_transform(vectorized_text)\n",
    "    else:\n",
    "        # Use LSA\n",
    "        model = TruncatedSVD(n_components=n_topics,n_iter=500,random_state=0)\n",
    "        topic_assignments = model.fit_transform(vectorized_text)\n",
    "\n",
    "    # Get the main keywords and scores corresponding to each topic\n",
    "    vocab = vectorizer.get_feature_names_out()\n",
    "    topics = []\n",
    "    for comp in model.components_:\n",
    "        # Get the top keywords for each topic\n",
    "        sorted_words = [vocab[score] for score in np.argsort(comp)[::-1]][:n_words]\n",
    "        # Get the scores for each top keyword\n",
    "        sorted_scores = np.sort(comp)[::-1][:n_words]\n",
    "        words_scores = zip(sorted_words,sorted_scores)\n",
    "        topics.append(words_scores)\n",
    "\n",
    "    return topics, topic_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3682e9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 keywords: ['clean small', 'suite laptops', 'valet parking', 'besite contains', 'hotel worked']\n",
      "Topic 1 keywords: ['girlfriend', 'taxi', 'deals', 'funny', 'speak']\n",
      "Topic 2 keywords: ['curtain', 'remodeled', 'bell', 'couch separated', 'double bed']\n",
      "Topic 3 keywords: ['husband', 'fan', 'husband 175', 'restaurant', 'glass']\n",
      "Topic 4 keywords: ['sheets', 'soiled sheets', 'feel home', 'feel', 'make feel']\n",
      "Topic 5 keywords: ['reception', 'smart', '1st', 'wakeup', 'bed']\n",
      "Topic 6 keywords: ['desk manager', 'lbs husband', 'website', '1st', 'staffnegatives ac']\n",
      "Topic 7 keywords: ['nice', 'parking', 'music room', 'nice goldfish', 'valet']\n",
      "Topic 8 keywords: ['website', 'guest', 'email', 'description', 'told']\n",
      "Topic 9 keywords: ['building', 'street', 'plenty', 'husband spent', 'dining']\n",
      "\n",
      "Article assignments:\n",
      "nice hotel expensive parking got good deal stay hotel anniversary, arrived late evening took advice previous reviews did valet parking, check quick easy, little disappointed non-existent view room room clean nice size, bed comfortable woke stiff neck high pillows, not soundproof like heard music room night morning loud bangs doors opening closing hear people talking hallway, maybe just noisy neighbors, aveda bath products nice, did not goldfish stay nice touch taken advantage staying longer, location great walking distance shopping, overall nice experience having pay 40 parking night,  \n",
      "Topic 0: 0.008, Topic 1: 0.008\n",
      "\n",
      "ok nothing special charge diamond member hilton decided chain shot 20th anniversary seattle, start booked suite paid extra website description not, suite bedroom bathroom standard hotel room, took printed reservation desk showed said things like tv couch ect desk clerk told oh mixed suites description kimpton website sorry free breakfast, got kidding, embassy suits sitting room bathroom bedroom unlike kimpton calls suite, 5 day stay offer correct false advertising, send kimpton preferred guest website email asking failure provide suite advertised website reservation description furnished hard copy reservation printout website desk manager duty did not reply solution, send email trip guest survey did not follow email mail, guess tell concerned guest.the staff ranged indifferent not helpful, asked desk good breakfast spots neighborhood hood told no hotels, gee best breakfast spots seattle 1/2 block away convenient hotel does not know exist, arrived late night 11 pm inside run bellman busy chating cell phone help bags.prior arrival emailed hotel inform 20th anniversary half really picky wanted make sure good, got nice email saying like deliver bottle champagne chocolate covered strawberries room arrival celebrate, told needed foam pillows, arrival no champagne strawberries no foam pillows great room view alley high rise building good not better housekeeping staff cleaner room property, impressed left morning shopping room got short trips 2 hours, beds comfortable.not good ac-heat control 4 x 4 inch screen bring green shine directly eyes night, light sensitive tape controls.this not 4 start hotel clean business hotel super high rates, better chain hotels seattle,  \n",
      "Topic 0: 0.005, Topic 1: 0.005\n",
      "\n",
      "nice rooms not 4* experience hotel monaco seattle good hotel n't 4* level.positives large bathroom mediterranean suite comfortable bed pillowsattentive housekeeping staffnegatives ac unit malfunctioned stay desk disorganized, missed 3 separate wakeup calls, concierge busy hard touch, did n't provide guidance special requests.tv hard use ipod sound dock suite non functioning. decided book mediterranean suite 3 night weekend stay 1st choice rest party filled, comparison w spent 45 night larger square footage room great soaking tub whirlpool jets nice shower.before stay hotel arrange car service price 53 tip reasonable driver waiting arrival.checkin easy downside room picked 2 person jacuzi tub no bath accessories salts bubble bath did n't stay, night got 12/1a checked voucher bottle champagne nice gesture fish waiting room, impression room huge open space felt room big, tv far away bed chore change channel, ipod dock broken disappointing.in morning way asked desk check thermostat said 65f 74 2 degrees warm try cover face night bright blue light kept, got room night no, 1st drop desk, called maintainence came look thermostat told play settings happy digital box wo n't work, asked wakeup 10am morning did n't happen, called later 6pm nap wakeup forgot, 10am wakeup morning yep forgotten.the bathroom facilities great room surprised room sold whirlpool bath tub n't bath amenities, great relax water jets going,  \n",
      "Topic 0: 0.005, Topic 1: 0.005\n",
      "\n",
      "unique, great stay, wonderful time hotel monaco, location excellent short stroll main downtown shopping area, pet friendly room showed no signs animal hair smells, monaco suite sleeping area big striped curtains pulled closed nice touch felt cosy, goldfish named brandi enjoyed, did n't partake free wine coffee/tea service lobby thought great feature, great staff friendly, free wireless internet hotel worked suite 2 laptops, decor lovely eclectic mix pattens color palatte, animal print bathrobes feel like rock stars, nice did n't look like sterile chain hotel hotel personality excellent stay,  \n",
      "Topic 0: 0.008, Topic 1: 0.008\n",
      "\n",
      "great stay great stay, went seahawk game awesome, downfall view building did n't complain, room huge staff helpful, booked hotels website seahawk package, no charge parking got voucher taxi, problem taxi driver did n't want accept voucher barely spoke english, funny thing speak arabic called started making comments girlfriend cell phone buddy, took second realize just said fact speak language face priceless, ass told, said large city, told head doorman issue called cab company promply answer did n't, apologized offered pay taxi, bucks 2 miles stadium, game plan taxi return going humpin, great walk did n't mind, right christmas wonderful lights, homeless stowed away building entrances leave, police presence not greatest area stadium, activities 7 blocks pike street waterfront great coffee shops way, hotel mantained foyer awesome, wine tasting available evening, best dog, taking st. bernard time family, safes hotel located service desk room, bathroom huge jetted tub huge, funny house keeping walked girlfriend getting dressed, did n't hear knock doing turn service, screamed girlfriend screams hit floor laughing, started talking spanish worked, place recommend price, check online deals just good not better, besite contains deals vouchers travel websites n't tell,  \n",
      "Topic 0: 0.006, Topic 1: 0.950\n",
      "\n",
      "love monaco staff husband stayed hotel crazy weekend attending memorial service best friend husband celebrating 12th wedding anniversary, talk mixed emotions, booked suite hotel monte carlos, loaned beautiful fan-tanned goldfish named joliet weekend visited dogs worked desk human companions, room decorated nicely couch used pillows, l'occitane bath amenities welcome sight, room quiet peaceful, wireless internet access wonderful server went morning leaving problems printing boarding passes, afternoon reception serves oenophile-satisfying wine australia scrumptious cookies, restaurant closed renovation stay finally ate food good drinks better, word caution restaurant larger person not sit booths wo n't fit, 5'6 125 lbs husband 5'9 175. table smack-against stomach couple inches space mighty uncomfortable patron larger pregnant, bad design opinion place decorated funky welcoming way metal wood handblown glass light fixtures expect seattle capital glass art industry, definitely stay reason,  \n",
      "Topic 0: 0.006, Topic 1: 0.006\n",
      "\n",
      "cozy stay rainy city, husband spent 7 nights monaco early january 2008. business trip chance come ride.we booked monte carlo suite proved comfortable longish stay, room 905 located street building, street noise not problem view interesting rooms building look dank alley midsection large office building, suite comfortable plenty room spread, bathroom attractive squeaky clean small comparison generous proportions sitting sleeping areas, lots comfortable seating options good lighting plenty storage clothing luggage, hotel staff friendly efficient, housekeeping staff did great job pleasant, requests responded quickly.the location quite good, easy walk pike street market seattle art museum notch shopping dining options.a positive experience,  \n",
      "Topic 0: 0.007, Topic 1: 0.007\n",
      "\n",
      "excellent staff, housekeeping quality hotel chocked staff make feel home, experienced exceptional service desk staff concierge door men maid service needs work, maid failed tuck sheets foot bed instance soiled sheets used, staff quickley resolved soiled sheets issue, guess relates employee not reflection rest staff.we received excellent advice concierge regarding resturants area happy hour wine tasting nice touch staff went way make feel home.great location like close good food shopping took play 5th street theather well.pikes market pioneer square access mono rail short walking distance,  \n",
      "Topic 0: 0.008, Topic 1: 0.008\n",
      "\n",
      "hotel stayed hotel monaco cruise, rooms generous decorated uniquely, hotel remodeled pacific bell building charm sturdiness, everytime walked bell men felt like coming home, secure, great single travelers, location fabulous, walk things pike market space needle.little grocery/drug store block away, today green, bravo, 1 double bed room room bed couch separated curtain, snoring mom slept curtain, great food nearby,  \n",
      "Topic 0: 0.009, Topic 1: 0.009\n",
      "\n",
      "excellent stayed hotel monaco past w/e delight, reception staff friendly professional room smart comfortable bed, particularly liked reception small dog received staff guests spoke loved, mild negative distance uphill ppmarket restaurants 1st, overall great experience,  \n",
      "Topic 0: 0.011, Topic 1: 0.011\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_vecs, vectorizer = vectorize(article_text,vectorizer_type='tfidf')\n",
    "topics,topic_assignments = model_topics(feature_vecs,vectorizer,n_topics=10,n_words=5,model_type='lda')\n",
    "for i,topic in enumerate(topics):\n",
    "    print('Topic {} keywords: {}'.format(i,[word[0] for word in topic]))\n",
    "\n",
    "print('\\nArticle assignments:')\n",
    "for i, j in enumerate(article_text):\n",
    "    print(j)\n",
    "    #print('Article {}: {}'.format(i,title))\n",
    "    print(\"Topic 0: {:.3f}, Topic 1: {:.3f}\".format(topic_assignments[i][0],topic_assignments[i][1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d7a474",
   "metadata": {},
   "source": [
    "## Post-process topics\n",
    "We may want to do some post-processing on the topics which our topic model identifies.  For example, we may have cases where a 1-gram is included twice in our keyword list for a topic - once by itself and then again as part of a 2-gram.  We may choose to remove the 1-gram if the word is included in a 2-gram since the two-gram may be more descriptive (e.g. \"random\" and \"random forest\").  We may also want to check and make sure we don't have any numeric-only keywords listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a33d636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedupe_topics(topics,n_words):\n",
    "    newtopics = []\n",
    "    wordsused = []\n",
    "    for topic in topics:\n",
    "        newkeywords = []\n",
    "        keywords = [word[0] for word in topic]\n",
    "        for word in keywords:\n",
    "            # Remove words that contain only digits\n",
    "            if word.isdigit():\n",
    "                continue\n",
    "            # Remove 1-gram if word is included in a 2-gram\n",
    "            elif sum([word in x for x in keywords])==1:\n",
    "                newkeywords.append(word)\n",
    "        newtopics.append(newkeywords[:n_words])\n",
    "    return newtopics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9465d724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 keywords: ['duke', 'scheyer', 'cbs', 'coach', 'blue devils']\n",
      "Topic 1 keywords: ['symptoms', 'coronavirus', 'flu', 'people', 'torres']\n"
     ]
    }
   ],
   "source": [
    "feature_vecs, vectorizer = vectorize(article_text,vectorizer_type='tfidf')\n",
    "topics = model_topics(feature_vecs,vectorizer,n_topics=2,n_words=15,model_type='lda')\n",
    "deduped_topics = dedupe_topics(topics,n_words=5)\n",
    "for i,keywords in enumerate(deduped_topics):\n",
    "    print('Topic {} keywords: {}'.format(i,keywords))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aipi540",
   "language": "python",
   "name": "aipi540"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
